{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lt9S1hujdDJX"
   },
   "source": [
    "# Gradio & HuggingFace Transformers Tutorial\n",
    "\n",
    "A comprehensive tutorial on building interactive machine learning applications using Gradio and HuggingFace Transformers, designed for Google Colab.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Setup Instructions](#setup-instructions)\n",
    "- [Part 1: Gradio Basics](#part-1-gradio-basics)\n",
    "- [Part 2: HuggingFace Integration](#part-2-huggingface-integration)\n",
    "- [Key Concepts](#key-concepts)\n",
    "- [Troubleshooting](#troubleshooting)\n",
    "- [Resources](#resources)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers:\n",
    "\n",
    "1. **Gradio Fundamentals**: Learn to build interactive UIs with rows, columns, images, input fields, and sliders\n",
    "2. **Creative Application**: Build a \"Mood-Based Color Palette Generator\" that creates color schemes based on user preferences\n",
    "3. **HuggingFace Integration**: Develop an \"AI Creative Studio\" combining sentiment analysis, image captioning, and text generation\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "### Running in Google Colab\n",
    "\n",
    "1. Open a new Colab notebook: [colab.research.google.com](https://colab.research.google.com)\n",
    "2. Install required libraries:\n",
    "\n",
    "```python\n",
    "!pip install gradio transformers torch pillow\n",
    "```\n",
    "\n",
    "3. Copy and run the code cells from this tutorial\n",
    "4. Click the generated public URL to access your app\n",
    "\n",
    "### Local Installation (Optional)\n",
    "\n",
    "```bash\n",
    "pip install gradio transformers torch pillow\n",
    "```\n",
    "\n",
    "## Part 1: Gradio Basics\n",
    "\n",
    "### What is Gradio?\n",
    "\n",
    "Gradio is a Python library that enables you to quickly create web interfaces for machine learning models or any Python function. It's particularly popular for:\n",
    "\n",
    "- Rapid prototyping of ML demos\n",
    "- Creating shareable interfaces without web development knowledge\n",
    "- Integration with HuggingFace Spaces for deployment\n",
    "\n",
    "### Core Components\n",
    "\n",
    "**Layout Components:**\n",
    "- `gr.Blocks()`: Main container for custom layouts\n",
    "- `gr.Row()`: Horizontal layout\n",
    "- `gr.Column()`: Vertical layout\n",
    "- `gr.Tab()`: Tabbed interface\n",
    "\n",
    "**Input/Output Components:**\n",
    "- `gr.Textbox()`: Text input/output\n",
    "- `gr.Slider()`: Numeric slider\n",
    "- `gr.Image()`: Image upload/display\n",
    "- `gr.Dropdown()`: Selection menu\n",
    "- `gr.Button()`: Clickable button\n",
    "- `gr.Gallery()`: Image grid display\n",
    "\n",
    "### Example: Mood-Based Color Palette Generator\n",
    "\n",
    "This creative application generates harmonious color palettes based on:\n",
    "- User's mood selection\n",
    "- Temperature preference (warm/cool)\n",
    "- Saturation level\n",
    "- Number of colors\n",
    "\n",
    "The app demonstrates:\n",
    "- Complex layouts with rows and columns\n",
    "- Multiple input types (dropdown, slider, radio)\n",
    "- Dynamic image generation\n",
    "- Real-time updates\n",
    "\n",
    "**Key Features:**\n",
    "- Predefined mood-to-color mappings\n",
    "- HSV color space manipulation for harmony\n",
    "- PIL-based palette visualization\n",
    "- Responsive design with organized sections\n",
    "\n",
    "## Part 2: HuggingFace Integration\n",
    "\n",
    "### What is HuggingFace Transformers?\n",
    "\n",
    "HuggingFace Transformers is a library providing pre-trained models for:\n",
    "- Natural Language Processing (NLP)\n",
    "- Computer Vision\n",
    "- Audio Processing\n",
    "- Multimodal tasks\n",
    "\n",
    "### Pipelines API\n",
    "\n",
    "The `pipeline()` function provides simple access to models:\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Sentiment Analysis\n",
    "sentiment = pipeline(\"sentiment-analysis\")\n",
    "result = sentiment(\"I love this tutorial!\")\n",
    "\n",
    "# Image Captioning\n",
    "captioner = pipeline(\"image-to-text\")\n",
    "caption = captioner(\"image.jpg\")\n",
    "\n",
    "# Text Generation\n",
    "generator = pipeline(\"text-generation\")\n",
    "text = generator(\"Once upon a time\")\n",
    "```\n",
    "\n",
    "### Example: AI Creative Studio\n",
    "\n",
    "This application combines three AI capabilities:\n",
    "\n",
    "1. **Sentiment Analyzer**: Analyzes emotional tone of text\n",
    "2. **Image Storyteller**: Generates captions and creative stories from images\n",
    "3. **Creative Writer**: Generates stories from prompts\n",
    "\n",
    "**Models Used:**\n",
    "- `distilbert-base-uncased-finetuned-sst-2-english`: Fast sentiment analysis\n",
    "- `Salesforce/blip-image-captioning-base`: Image understanding\n",
    "- `gpt2`: Text generation\n",
    "\n",
    "**Technical Highlights:**\n",
    "- Multiple pipeline integration\n",
    "- Error handling for model loading\n",
    "- Tabbed interface for organization\n",
    "- Image upload and processing\n",
    "- Adjustable generation parameters\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### Gradio Interface Patterns\n",
    "\n",
    "**Simple Interface:**\n",
    "```python\n",
    "gr.Interface(fn=function, inputs=..., outputs=...)\n",
    "```\n",
    "\n",
    "**Custom Blocks:**\n",
    "```python\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        input_col = gr.Column()\n",
    "        output_col = gr.Column()\n",
    "```\n",
    "\n",
    "### Event Handling\n",
    "\n",
    "Connect components with `.click()`, `.change()`, `.submit()`:\n",
    "\n",
    "```python\n",
    "button.click(fn=process, inputs=[input1, input2], outputs=output)\n",
    "```\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Error Handling**: Wrap model calls in try-except blocks\n",
    "2. **Loading States**: Show progress for long operations\n",
    "3. **Clear Descriptions**: Use `label` and `info` parameters\n",
    "4. **Responsive Design**: Use rows/columns for proper layout\n",
    "5. **Resource Management**: Load heavy models once, not per request\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**Issue**: ModuleNotFoundError\n",
    "**Solution**: Ensure all packages are installed: `!pip install gradio transformers torch pillow`\n",
    "\n",
    "**Issue**: CUDA out of memory\n",
    "**Solution**: Use CPU by not specifying device, or use smaller models\n",
    "\n",
    "**Issue**: Model download slow\n",
    "**Solution**: Models cache automatically. First run takes time; subsequent runs are faster\n",
    "\n",
    "**Issue**: Gradio tunnel not working\n",
    "**Solution**: Try `demo.launch(share=True, debug=True)` for more information\n",
    "\n",
    "### Memory Optimization\n",
    "\n",
    "For Colab's free tier:\n",
    "- Use smaller models (distilbert instead of bert)\n",
    "- Set `low_cpu_mem_usage=True` when loading models\n",
    "- Clear outputs regularly: `Runtime > Manage Sessions`\n",
    "\n",
    "## Resources\n",
    "\n",
    "### Official Documentation\n",
    "- [Gradio Docs](https://www.gradio.app/docs)\n",
    "- [HuggingFace Transformers](https://huggingface.co/docs/transformers)\n",
    "- [HuggingFace Models](https://huggingface.co/models)\n",
    "\n",
    "### Useful Links\n",
    "- [Gradio Guides](https://www.gradio.app/guides)\n",
    "- [Pipeline Task Documentation](https://huggingface.co/docs/transformers/task_summary)\n",
    "- [Gradio on HuggingFace Spaces](https://huggingface.co/spaces)\n",
    "\n",
    "### Further Learning\n",
    "- Explore more models at [HuggingFace Hub](https://huggingface.co/models)\n",
    "- Join [HuggingFace Discord](https://discord.com/invite/hugging-face)\n",
    "- Check [Gradio Community](https://github.com/gradio-app/gradio/discussions)\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "After completing this tutorial, you will be able to:\n",
    "\n",
    "Build custom Gradio interfaces with complex layouts\n",
    "Integrate multiple input and output components\n",
    "Use HuggingFace pipelines for various AI tasks\n",
    "Combine multiple models in a single application\n",
    "Deploy interactive demos in Google Colab\n",
    "Handle images and text with AI models\n",
    "Create shareable ML applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation complete! Ready to build apps.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gradio transformers torch pillow\n",
    "\n",
    "print(\"Installation complete! Ready to build apps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a8ZhAF3ddq_"
   },
   "source": [
    "# We'll build a \"Mood-Based Color Palette Generator\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_color_palette(mood, temperature, saturation, num_colors):\n",
    "    \"\"\"\n",
    "    Generates a harmonious color palette based on mood and preferences.\n",
    "\n",
    "    Args:\n",
    "        mood: Base emotion (happy, calm, energetic, melancholic, creative)\n",
    "        temperature: Warm or cool colors\n",
    "        saturation: Color intensity (0-100)\n",
    "        num_colors: Number of colors to generate (3-8)\n",
    "\n",
    "    Returns:\n",
    "        PIL Image of the color palette with hex codes\n",
    "    \"\"\"\n",
    "\n",
    "    # Define base hues for each mood (0-360 degrees)\n",
    "    mood_hues = {\n",
    "        \"Happy\": 45,      # Yellow-Orange\n",
    "        \"Calm\": 200,      # Blue\n",
    "        \"Energetic\": 0,   # Red\n",
    "        \"Melancholic\": 240,  # Purple\n",
    "        \"Creative\": 280   # Magenta\n",
    "    }\n",
    "\n",
    "    # Get base hue\n",
    "    base_hue = mood_hues[mood]\n",
    "\n",
    "    # Adjust for temperature\n",
    "    if temperature == \"Warm\":\n",
    "        base_hue = (base_hue - 30) % 360  # Shift toward red-yellow\n",
    "    else:  # Cool\n",
    "        base_hue = (base_hue + 30) % 360  # Shift toward blue-green\n",
    "\n",
    "    # Convert saturation from 0-100 to 0-1\n",
    "    sat = saturation / 100.0\n",
    "\n",
    "    # Generate harmonious colors using different strategies\n",
    "    colors = []\n",
    "    for i in range(num_colors):\n",
    "        # Create variation using analogous colors (nearby hues)\n",
    "        hue_variation = (base_hue + (i * 30)) % 360\n",
    "\n",
    "        # Slight saturation and value variations for interest\n",
    "        s = max(0.3, min(1.0, sat + (i % 2) * 0.1))\n",
    "        v = 0.85 + (i % 3) * 0.05\n",
    "\n",
    "        # Convert HSV to RGB\n",
    "        r, g, b = colorsys.hsv_to_rgb(hue_variation / 360.0, s, v)\n",
    "        colors.append((int(r * 255), int(g * 255), int(b * 255)))\n",
    "\n",
    "    # Create image to display palette\n",
    "    palette_width = 600\n",
    "    palette_height = 400\n",
    "    swatch_height = palette_height // 2\n",
    "\n",
    "    img = Image.new('RGB', (palette_width, palette_height), 'white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Draw color swatches\n",
    "    swatch_width = palette_width // num_colors\n",
    "    for i, color in enumerate(colors):\n",
    "        x0 = i * swatch_width\n",
    "        x1 = (i + 1) * swatch_width\n",
    "        draw.rectangle([x0, 0, x1, swatch_height], fill=color)\n",
    "\n",
    "        # Add hex code labels\n",
    "        hex_code = '#{:02x}{:02x}{:02x}'.format(*color)\n",
    "\n",
    "        # Calculate text position\n",
    "        text_bbox = draw.textbbox((0, 0), hex_code)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_x = x0 + (swatch_width - text_width) // 2\n",
    "        text_y = swatch_height + 20\n",
    "\n",
    "        # Draw text with background for readability\n",
    "        draw.rectangle([text_x - 5, text_y - 5, text_x + text_width + 5, text_y + 20],\n",
    "                      fill='white')\n",
    "        draw.text((text_x, text_y), hex_code, fill='black')\n",
    "\n",
    "        # Draw RGB values\n",
    "        rgb_text = f\"RGB({color[0]}, {color[1]}, {color[2]})\"\n",
    "        rgb_bbox = draw.textbbox((0, 0), rgb_text)\n",
    "        rgb_width = rgb_bbox[2] - rgb_bbox[0]\n",
    "        rgb_x = x0 + (swatch_width - rgb_width) // 2\n",
    "        rgb_y = text_y + 30\n",
    "\n",
    "        draw.text((rgb_x, rgb_y), rgb_text, fill='gray')\n",
    "\n",
    "    # Add title\n",
    "    title = f\"{mood} {temperature} Palette\"\n",
    "    title_bbox = draw.textbbox((0, 0), title)\n",
    "    title_width = title_bbox[2] - title_bbox[0]\n",
    "    draw.text((palette_width // 2 - title_width // 2, swatch_height + 80),\n",
    "             title, fill='black')\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-967299074.py:2: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
      "  with gr.Blocks(title=\"Mood Color Palette Generator\", theme=gr.themes.Soft()) as demo_basic:\n"
     ]
    }
   ],
   "source": [
    "# Build the Gradio interface with custom layout\n",
    "with gr.Blocks(title=\"Mood Color Palette Generator\", theme=gr.themes.Soft()) as demo_basic:\n",
    "\n",
    "    # Header\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üé® Mood-Based Color Palette Generator\n",
    "    Create beautiful, harmonious color palettes based on your mood and preferences!\n",
    "    \"\"\")\n",
    "\n",
    "    # Main layout with two columns\n",
    "    with gr.Row():\n",
    "        # Left column: Inputs\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### ‚öôÔ∏è Palette Settings\")\n",
    "\n",
    "            mood_input = gr.Dropdown(\n",
    "                choices=[\"Happy\", \"Calm\", \"Energetic\", \"Melancholic\", \"Creative\"],\n",
    "                value=\"Happy\",\n",
    "                label=\"Choose Your Mood\",\n",
    "                info=\"Select the emotion you want to express\"\n",
    "            )\n",
    "\n",
    "            temperature_input = gr.Radio(\n",
    "                choices=[\"Warm\", \"Cool\"],\n",
    "                value=\"Warm\",\n",
    "                label=\"Color Temperature\",\n",
    "                info=\"Warm colors (reds, oranges) vs Cool colors (blues, greens)\"\n",
    "            )\n",
    "\n",
    "            saturation_input = gr.Slider(\n",
    "                minimum=0,\n",
    "                maximum=100,\n",
    "                value=70,\n",
    "                step=5,\n",
    "                label=\"Saturation Level\",\n",
    "                info=\"How intense should the colors be? (0=gray, 100=vivid)\"\n",
    "            )\n",
    "\n",
    "            num_colors_input = gr.Slider(\n",
    "                minimum=3,\n",
    "                maximum=8,\n",
    "                value=5,\n",
    "                step=1,\n",
    "                label=\"Number of Colors\",\n",
    "                info=\"How many colors in your palette?\"\n",
    "            )\n",
    "\n",
    "            generate_btn = gr.Button(\"üé® Generate Palette\", variant=\"primary\", size=\"lg\")\n",
    "\n",
    "        # Right column: Output\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Markdown(\"### üñºÔ∏è Your Color Palette\")\n",
    "            output_image = gr.Image(\n",
    "                label=\"Generated Palette\",\n",
    "                type=\"pil\",\n",
    "                height=400\n",
    "            )\n",
    "\n",
    "            gr.Markdown(\"\"\"\n",
    "            **üí° Tips:**\n",
    "            - Use warm colors for energy and excitement\n",
    "            - Cool colors create calm and professional vibes\n",
    "            - Lower saturation for subtle, elegant designs\n",
    "            - Higher saturation for bold, eye-catching visuals\n",
    "            \"\"\")\n",
    "\n",
    "    # Examples section\n",
    "    gr.Markdown(\"### üåü Try These Presets\")\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"Happy\", \"Warm\", 80, 5],\n",
    "            [\"Calm\", \"Cool\", 50, 4],\n",
    "            [\"Energetic\", \"Warm\", 95, 6],\n",
    "            [\"Melancholic\", \"Cool\", 40, 4],\n",
    "            [\"Creative\", \"Warm\", 75, 7],\n",
    "        ],\n",
    "        inputs=[mood_input, temperature_input, saturation_input, num_colors_input],\n",
    "        outputs=output_image,\n",
    "        fn=generate_color_palette,\n",
    "        cache_examples=False,\n",
    "    )\n",
    "\n",
    "    # Connect button to function\n",
    "    generate_btn.click(\n",
    "        fn=generate_color_palette,\n",
    "        inputs=[mood_input, temperature_input, saturation_input, num_colors_input],\n",
    "        outputs=output_image\n",
    "    )\n",
    "\n",
    "    # Also update on any input change for live preview\n",
    "    for input_component in [mood_input, temperature_input, saturation_input, num_colors_input]:\n",
    "        input_component.change(\n",
    "            fn=generate_color_palette,\n",
    "            inputs=[mood_input, temperature_input, saturation_input, num_colors_input],\n",
    "            outputs=output_image\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PART 1: GRADIO BASICS - Launching Color Palette Generator...\n",
      "======================================================================\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://23c43623286f52c26b.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://23c43623286f52c26b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 1: GRADIO BASICS - Launching Color Palette Generator...\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "demo_basic.launch(share=True, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PART 2: Loading HuggingFace Models...\n",
      "======================================================================\n",
      "\n",
      "Using device: GPU (CUDA)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PART 2: HUGGINGFACE TRANSFORMERS INTEGRATION\n",
    "# ============================================================================\n",
    "# We'll build an \"AI Creative Studio\" with multiple AI models\n",
    "# ============================================================================\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2: Loading HuggingFace Models...\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Using device: {'GPU (CUDA)' if device == 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Loading AI models... (this may take 1-2 minutes)\n",
      "  Loading sentiment analyzer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82d79a7eb73488eba351a2f9f71c2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9873fcd53a9e428aa61abeda5633fca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfb0e0087de4438bba65f0c81cde0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2365199b2c8e493fbd0e77fff0e9daf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment analyzer loaded\n",
      "  Loading image captioner...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceab2381299e44acbedde8be78388dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a87f1ec9efa44c4bcfe5cc532fee4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b00d3f4c1be43588dc1f0a2966747c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b24ad83cc64f7abada246e12d909aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc353a7f9ae24999abe25ec50b1a2d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72de6fe6ca7a44b2a7e822683fff0b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdafd6fa85384accb9a28e6de29a97f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26fcabe118f40fea61d261e44033697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Image captioner loaded\n",
      "  Loading text generator...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77e043de6b54ff0aec5841f611290ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e18ab5fdea49f0bbdc8420694082a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d827c0afe96454586f9d3f16d2a9310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17288d10e33e43d2bdd8c5d40ba44953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04f0c6a8fa34142848065bfaaf86e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6dc754dba04c2d822b20d14e08e385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26b1a04175846b2abd246bb8ddaf0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text generator loaded\n",
      "\n",
      " All models loaded successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load models (this may take a minute on first run)\n",
    "print(\"\\n‚è≥ Loading AI models... (this may take 1-2 minutes)\")\n",
    "\n",
    "try:\n",
    "    # Sentiment Analysis\n",
    "    print(\"  Loading sentiment analyzer...\")\n",
    "    sentiment_analyzer = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "        device=device\n",
    "    )\n",
    "    print(\"  Sentiment analyzer loaded\")\n",
    "\n",
    "    # Image Captioning\n",
    "    print(\"  Loading image captioner...\")\n",
    "    image_captioner = pipeline(\n",
    "        \"image-to-text\",\n",
    "        model=\"Salesforce/blip-image-captioning-base\",\n",
    "        device=device\n",
    "    )\n",
    "    print(\"  Image captioner loaded\")\n",
    "\n",
    "    # Text Generation\n",
    "    print(\"  Loading text generator...\")\n",
    "    text_generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=\"gpt2\",\n",
    "        device=device\n",
    "    )\n",
    "    print(\"  Text generator loaded\")\n",
    "\n",
    "    print(\"\\n All models loaded successfully!\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n Error loading models: {e}\")\n",
    "    print(\" Try restarting runtime if you encounter memory issues\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions for each AI feature\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"Analyze sentiment of input text\"\"\"\n",
    "    if not text or text.strip() == \"\":\n",
    "        return \"Please enter some text to analyze.\", None\n",
    "\n",
    "    try:\n",
    "        result = sentiment_analyzer(text)[0]\n",
    "        label = result['label']\n",
    "        score = result['score']\n",
    "\n",
    "        # Create a visual representation\n",
    "        sentiment_emoji = \"üòä\" if label == \"POSITIVE\" else \"üòî\"\n",
    "        confidence = f\"{score * 100:.1f}%\"\n",
    "\n",
    "        output = f\"\"\"\n",
    "### Analysis Results {sentiment_emoji}\n",
    "\n",
    "**Sentiment:** {label}\n",
    "**Confidence:** {confidence}\n",
    "\n",
    "The text expresses a **{label.lower()}** sentiment with {confidence} confidence.\n",
    "        \"\"\"\n",
    "\n",
    "        return output, result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", None\n",
    "\n",
    "def caption_and_story(image, creativity):\n",
    "    \"\"\"Generate caption and creative story from image\"\"\"\n",
    "    if image is None:\n",
    "        return \"Please upload an image.\", \"\"\n",
    "\n",
    "    try:\n",
    "        # Generate caption\n",
    "        caption_result = image_captioner(image)[0]['generated_text']\n",
    "\n",
    "        # Generate creative story based on the caption\n",
    "        story_prompt = f\"Write a short creative story about: {caption_result}\"\n",
    "\n",
    "        story_result = text_generator(\n",
    "            story_prompt,\n",
    "            max_length=150,\n",
    "            num_return_sequences=1,\n",
    "            temperature=creativity,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95\n",
    "        )[0]['generated_text']\n",
    "\n",
    "        # Clean up the story\n",
    "        story = story_result.replace(story_prompt, \"\").strip()\n",
    "\n",
    "        return f\"**Caption:** {caption_result}\", story\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", \"\"\n",
    "\n",
    "def generate_creative_text(prompt, length, creativity):\n",
    "    \"\"\"Generate creative text from prompt\"\"\"\n",
    "    if not prompt or prompt.strip() == \"\":\n",
    "        return \"Please enter a prompt to generate text.\"\n",
    "\n",
    "    try:\n",
    "        # Calculate max_length based on user input\n",
    "        max_length = min(length, 200)  # Cap at 200 tokens\n",
    "\n",
    "        result = text_generator(\n",
    "            prompt,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            temperature=creativity,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=text_generator.tokenizer.eos_token_id\n",
    "        )[0]['generated_text']\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-867666137.py:2: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
      "  with gr.Blocks(title=\"AI Creative Studio\", theme=gr.themes.Base()) as demo_ai:\n"
     ]
    }
   ],
   "source": [
    "# Build the AI Creative Studio interface\n",
    "with gr.Blocks(title=\"AI Creative Studio\", theme=gr.themes.Base()) as demo_ai:\n",
    "\n",
    "    # Header\n",
    "    gr.Markdown(\"\"\"\n",
    "    # ü§ñ AI Creative Studio\n",
    "    ### Powered by HuggingFace Transformers\n",
    "\n",
    "    Explore the capabilities of state-of-the-art AI models for sentiment analysis,\n",
    "    image understanding, and creative writing!\n",
    "    \"\"\")\n",
    "\n",
    "    # Tabs for different AI features\n",
    "    with gr.Tabs():\n",
    "\n",
    "        # Tab 1: Sentiment Analysis\n",
    "        with gr.Tab(\" Sentiment Analyzer\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Analyze the emotional tone of any text\n",
    "            This uses a DistilBERT model fine-tuned for sentiment classification.\n",
    "            \"\"\")\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    sentiment_input = gr.Textbox(\n",
    "                        label=\"Enter Text to Analyze\",\n",
    "                        placeholder=\"Type or paste any text here...\",\n",
    "                        lines=5\n",
    "                    )\n",
    "                    sentiment_btn = gr.Button(\"Analyze Sentiment\", variant=\"primary\")\n",
    "\n",
    "                    gr.Examples(\n",
    "                        examples=[\n",
    "                            \"I absolutely love this tutorial! It's so helpful and well-explained.\",\n",
    "                            \"This is the worst experience I've ever had. Very disappointed.\",\n",
    "                            \"The weather today is okay, nothing special.\",\n",
    "                            \"I'm excited about learning AI and building cool projects!\",\n",
    "                        ],\n",
    "                        inputs=sentiment_input,\n",
    "                    )\n",
    "\n",
    "                with gr.Column():\n",
    "                    sentiment_output = gr.Markdown(label=\"Analysis Results\")\n",
    "\n",
    "            sentiment_btn.click(\n",
    "                fn=analyze_sentiment,\n",
    "                inputs=sentiment_input,\n",
    "                outputs=[sentiment_output, gr.JSON(visible=False)]\n",
    "            )\n",
    "\n",
    "        # Tab 2: Image Storyteller\n",
    "        with gr.Tab(\"Image Storyteller\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Transform images into captions and creative stories\n",
    "            Upload an image and watch AI describe it and create a story!\n",
    "            \"\"\")\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    image_input = gr.Image(\n",
    "                        label=\"Upload an Image\",\n",
    "                        type=\"pil\",\n",
    "                        height=300\n",
    "                    )\n",
    "\n",
    "                    creativity_slider = gr.Slider(\n",
    "                        minimum=0.5,\n",
    "                        maximum=1.5,\n",
    "                        value=1.0,\n",
    "                        step=0.1,\n",
    "                        label=\"Creativity Level\",\n",
    "                        info=\"Higher = more creative/unexpected stories\"\n",
    "                    )\n",
    "\n",
    "                    caption_btn = gr.Button(\"‚ú® Generate Caption & Story\", variant=\"primary\")\n",
    "\n",
    "                with gr.Column():\n",
    "                    caption_output = gr.Markdown(label=\"Image Caption\")\n",
    "                    story_output = gr.Textbox(\n",
    "                        label=\"Creative Story\",\n",
    "                        lines=8,\n",
    "                        interactive=False\n",
    "                    )\n",
    "\n",
    "            caption_btn.click(\n",
    "                fn=caption_and_story,\n",
    "                inputs=[image_input, creativity_slider],\n",
    "                outputs=[caption_output, story_output]\n",
    "            )\n",
    "\n",
    "        # Tab 3: Creative Writer\n",
    "        with gr.Tab(\"Creative Writer\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Generate creative text from your prompts\n",
    "            Start a story, continue a narrative, or explore creative ideas!\n",
    "            \"\"\")\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    prompt_input = gr.Textbox(\n",
    "                        label=\"Enter Your Prompt\",\n",
    "                        placeholder=\"Once upon a time in a distant galaxy...\",\n",
    "                        lines=3\n",
    "                    )\n",
    "\n",
    "                    with gr.Row():\n",
    "                        length_slider = gr.Slider(\n",
    "                            minimum=50,\n",
    "                            maximum=200,\n",
    "                            value=100,\n",
    "                            step=10,\n",
    "                            label=\"Length (tokens)\",\n",
    "                            info=\"Longer = more text generated\"\n",
    "                        )\n",
    "\n",
    "                        creativity_slider2 = gr.Slider(\n",
    "                            minimum=0.5,\n",
    "                            maximum=1.5,\n",
    "                            value=0.9,\n",
    "                            step=0.1,\n",
    "                            label=\"Creativity\",\n",
    "                            info=\"Higher = more surprising outputs\"\n",
    "                        )\n",
    "\n",
    "                    generate_btn = gr.Button(\"Generate Text\", variant=\"primary\")\n",
    "\n",
    "                    gr.Examples(\n",
    "                        examples=[\n",
    "                            \"In a world where AI and humans work together,\",\n",
    "                            \"The old lighthouse keeper discovered a mysterious message\",\n",
    "                            \"She opened the ancient book and found\",\n",
    "                            \"The robot looked at its reflection and wondered\",\n",
    "                        ],\n",
    "                        inputs=prompt_input,\n",
    "                    )\n",
    "\n",
    "                with gr.Column():\n",
    "                    text_output = gr.Textbox(\n",
    "                        label=\"Generated Text\",\n",
    "                        lines=12,\n",
    "                        interactive=False\n",
    "                    )\n",
    "\n",
    "            generate_btn.click(\n",
    "                fn=generate_creative_text,\n",
    "                inputs=[prompt_input, length_slider, creativity_slider2],\n",
    "                outputs=text_output\n",
    "            )\n",
    "\n",
    "    # Footer with model information\n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    ### üîß Models Used\n",
    "\n",
    "    - **Sentiment Analysis**: `distilbert-base-uncased-finetuned-sst-2-english`\n",
    "    - **Image Captioning**: `Salesforce/blip-image-captioning-base`\n",
    "    - **Text Generation**: `gpt2`\n",
    "\n",
    "    All models are from the [HuggingFace Model Hub](https://huggingface.co/models).\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PART 2: Launching AI Creative Studio...\n",
      "======================================================================\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://4bfc581bc148889613.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4bfc581bc148889613.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Launch the AI Studio\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2: Launching AI Creative Studio...\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "demo_ai.launch(share=True, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VAVXnwTe1t9"
   },
   "source": [
    "TUTORIAL COMPLETE!\n",
    "\n",
    "Congratulations! You've built two complete Gradio applications:\n",
    "\n",
    "1Ô∏è‚É£  Mood-Based Color Palette Generator\n",
    "   - Custom layouts with rows and columns\n",
    "   - Multiple input types (dropdown, radio, sliders)\n",
    "   - Dynamic image generation\n",
    "   \n",
    "2Ô∏è‚É£  AI Creative Studio\n",
    "   - Sentiment analysis with DistilBERT\n",
    "   - Image captioning with BLIP\n",
    "   - Text generation with GPT-2\n",
    "   - Tabbed interface organization\n",
    "\n",
    " Key Takeaways:\n",
    "   ‚úì Gradio makes it easy to build ML interfaces\n",
    "   ‚úì HuggingFace pipelines provide simple access to powerful models\n",
    "   ‚úì You can combine multiple models in one application\n",
    "   ‚úì share=True gives you a public URL to share your app\n",
    "\n",
    " Next Steps:\n",
    "   ‚Ä¢ Explore more models at huggingface.co/models\n",
    "   ‚Ä¢ Try different pipeline tasks (translation, summarization, etc.)\n",
    "   ‚Ä¢ Deploy to HuggingFace Spaces for permanent hosting\n",
    "   ‚Ä¢ Experiment with model parameters for different results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
